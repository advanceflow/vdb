root: INFO: Namespace(arch='resnet50', batch_size=64, bits='12,24,32,48', epochs=3, gamma=200, gpu='6', learning_rate=0.001, max_iter=50, num_samples=2000)
root: INFO: 12
root: INFO: [Comment: learning rate decay]
root: INFO: [Iteration:   0/ 50][Train Loss: 15.3279]
root: INFO: [Iteration:   1/ 50][Train Loss: 9.8814]
root: INFO: [Iteration:   2/ 50][Train Loss: 6.7057]
root: INFO: [Iteration:   3/ 50][Train Loss: 5.0369]
root: INFO: [Iteration:   4/ 50][Train Loss: 4.1676]
root: INFO: [Iteration:   5/ 50][Train Loss: 3.7236]
root: INFO: [Iteration:   6/ 50][Train Loss: 3.4824]
root: INFO: [Iteration:   7/ 50][Train Loss: 3.1704]
root: INFO: [Iteration:   8/ 50][Train Loss: 2.9608]
root: INFO: [Iteration:   9/ 50][Train Loss: 2.4324]
root: INFO: [Iteration:  10/ 50][Train Loss: 2.0355]
root: INFO: [Iteration:  11/ 50][Train Loss: 3.0939]
root: INFO: [Iteration:  12/ 50][Train Loss: 2.8423]
root: INFO: [Iteration:  13/ 50][Train Loss: 2.7950]
root: INFO: [Iteration:  14/ 50][Train Loss: 2.7736]
root: INFO: [Iteration:  15/ 50][Train Loss: 2.7341]
root: INFO: [Iteration:  16/ 50][Train Loss: 2.8610]
root: INFO: [Iteration:  17/ 50][Train Loss: 2.6800]
root: INFO: [Iteration:  18/ 50][Train Loss: 2.6829]
root: INFO: [Iteration:  19/ 50][Train Loss: 2.7486]
root: INFO: [Iteration:  20/ 50][Train Loss: 2.7604]
root: INFO: [Iteration:  21/ 50][Train Loss: 3.1305]
root: INFO: [Iteration:  22/ 50][Train Loss: 3.1563]
root: INFO: [Iteration:  23/ 50][Train Loss: 3.0656]
root: INFO: [Iteration:  24/ 50][Train Loss: 3.0380]
root: INFO: [Iteration:  25/ 50][Train Loss: 2.9325]
root: INFO: [Iteration:  26/ 50][Train Loss: 2.9241]
root: INFO: [Iteration:  27/ 50][Train Loss: 2.9541]
root: INFO: [Iteration:  28/ 50][Train Loss: 2.9662]
root: INFO: [Iteration:  29/ 50][Train Loss: 2.9052]
root: INFO: [Iteration:  30/ 50][Train Loss: 2.8514]
root: INFO: [Iteration:  31/ 50][Train Loss: 2.8773]
root: INFO: [Iteration:  32/ 50][Train Loss: 3.0487]
root: INFO: [Iteration:  33/ 50][Train Loss: 2.9697]
root: INFO: [Iteration:  34/ 50][Train Loss: 3.0439]
root: INFO: [Iteration:  35/ 50][Train Loss: 2.9359]
root: INFO: [Iteration:  36/ 50][Train Loss: 3.2029]
root: INFO: [Iteration:  37/ 50][Train Loss: 3.0748]
root: INFO: [Iteration:  38/ 50][Train Loss: 3.0108]
root: INFO: [Iteration:  39/ 50][Train Loss: 3.1986]
root: INFO: [Iteration:  40/ 50][Train Loss: 3.0519]
root: INFO: [Iteration:  41/ 50][Train Loss: 2.8520]
root: INFO: [Iteration:  42/ 50][Train Loss: 2.8708]
root: INFO: [Iteration:  43/ 50][Train Loss: 2.9454]
root: INFO: [Iteration:  44/ 50][Train Loss: 2.8676]
root: INFO: [Iteration:  45/ 50][Train Loss: 3.0355]
root: INFO: [Iteration:  46/ 50][Train Loss: 3.0988]
root: INFO: [Iteration:  47/ 50][Train Loss: 3.0183]
root: INFO: [Iteration:  48/ 50][Train Loss: 3.0394]
root: INFO: [Iteration:  49/ 50][Train Loss: 3.0115]
root: INFO: [Evaluation: mAP: 0.9473]
root: INFO: Namespace(arch='resnet50', batch_size=64, bits='12,24,32,48', epochs=3, gamma=200, gpu='6', learning_rate=0.001, max_iter=50, num_samples=2000)
root: INFO: 24
root: INFO: [Comment: learning rate decay]
root: INFO: [Iteration:   0/ 50][Train Loss: 60.4226]
root: INFO: [Iteration:   1/ 50][Train Loss: 23.2824]
root: INFO: [Iteration:   2/ 50][Train Loss: 6.2475]
root: INFO: [Iteration:   3/ 50][Train Loss: 4.5333]
root: INFO: [Iteration:   4/ 50][Train Loss: 3.8060]
root: INFO: [Iteration:   5/ 50][Train Loss: 3.0607]
root: INFO: [Iteration:   6/ 50][Train Loss: 3.5735]
root: INFO: [Iteration:   7/ 50][Train Loss: 3.2665]
root: INFO: [Iteration:   8/ 50][Train Loss: 3.1569]
root: INFO: [Iteration:   9/ 50][Train Loss: 2.7407]
root: INFO: [Iteration:  10/ 50][Train Loss: 2.9113]
root: INFO: [Iteration:  11/ 50][Train Loss: 4.9839]
root: INFO: [Iteration:  12/ 50][Train Loss: 4.7041]
root: INFO: [Iteration:  13/ 50][Train Loss: 4.6432]
root: INFO: [Iteration:  14/ 50][Train Loss: 4.3294]
root: INFO: [Iteration:  15/ 50][Train Loss: 4.7221]
root: INFO: [Iteration:  16/ 50][Train Loss: 4.1537]
root: INFO: [Iteration:  17/ 50][Train Loss: 4.3046]
root: INFO: [Iteration:  18/ 50][Train Loss: 3.9833]
root: INFO: [Iteration:  19/ 50][Train Loss: 4.5151]
root: INFO: [Iteration:  20/ 50][Train Loss: 4.0361]
root: INFO: [Iteration:  21/ 50][Train Loss: 6.4668]
root: INFO: [Iteration:  22/ 50][Train Loss: 6.4748]
root: INFO: [Iteration:  23/ 50][Train Loss: 5.9585]
root: INFO: [Iteration:  24/ 50][Train Loss: 6.5648]
root: INFO: [Iteration:  25/ 50][Train Loss: 6.2475]
root: INFO: [Iteration:  26/ 50][Train Loss: 5.7972]
root: INFO: [Iteration:  27/ 50][Train Loss: 5.8689]
root: INFO: [Iteration:  28/ 50][Train Loss: 5.8900]
root: INFO: [Iteration:  29/ 50][Train Loss: 5.9057]
root: INFO: [Iteration:  30/ 50][Train Loss: 6.3158]
root: INFO: [Iteration:  31/ 50][Train Loss: 6.6396]
root: INFO: [Iteration:  32/ 50][Train Loss: 7.3786]
root: INFO: [Iteration:  33/ 50][Train Loss: 6.3000]
root: INFO: [Iteration:  34/ 50][Train Loss: 6.9649]
root: INFO: [Iteration:  35/ 50][Train Loss: 6.3165]
root: INFO: [Iteration:  36/ 50][Train Loss: 6.8608]
root: INFO: [Iteration:  37/ 50][Train Loss: 6.0961]
root: INFO: [Iteration:  38/ 50][Train Loss: 6.2329]
root: INFO: [Iteration:  39/ 50][Train Loss: 6.7086]
root: INFO: [Iteration:  40/ 50][Train Loss: 6.4868]
root: INFO: [Iteration:  41/ 50][Train Loss: 6.0429]
root: INFO: [Iteration:  42/ 50][Train Loss: 6.5388]
root: INFO: [Iteration:  43/ 50][Train Loss: 6.7003]
root: INFO: [Iteration:  44/ 50][Train Loss: 5.9956]
root: INFO: [Iteration:  45/ 50][Train Loss: 6.6302]
root: INFO: [Iteration:  46/ 50][Train Loss: 6.8692]
root: INFO: [Iteration:  47/ 50][Train Loss: 7.0006]
root: INFO: [Iteration:  48/ 50][Train Loss: 7.0776]
root: INFO: [Iteration:  49/ 50][Train Loss: 6.2725]
root: INFO: [Evaluation: mAP: 0.9636]
root: INFO: Namespace(arch='resnet50', batch_size=64, bits='12,24,32,48', epochs=3, gamma=200, gpu='6', learning_rate=0.001, max_iter=50, num_samples=2000)
root: INFO: 32
root: INFO: [Comment: learning rate decay]
root: INFO: [Iteration:   0/ 50][Train Loss: 106.8856]
root: INFO: [Iteration:   1/ 50][Train Loss: 34.4108]
root: INFO: [Iteration:   2/ 50][Train Loss: 11.5157]
root: INFO: [Iteration:   3/ 50][Train Loss: 8.1772]
root: INFO: [Iteration:   4/ 50][Train Loss: 5.3273]
root: INFO: [Iteration:   5/ 50][Train Loss: 4.6127]
root: INFO: [Iteration:   6/ 50][Train Loss: 4.6157]
root: INFO: [Iteration:   7/ 50][Train Loss: 4.2299]
root: INFO: [Iteration:   8/ 50][Train Loss: 3.9431]
root: INFO: [Iteration:   9/ 50][Train Loss: 4.1150]
root: INFO: [Iteration:  10/ 50][Train Loss: 4.2863]
root: INFO: [Iteration:  11/ 50][Train Loss: 6.9176]
root: INFO: [Iteration:  12/ 50][Train Loss: 6.7651]
root: INFO: [Iteration:  13/ 50][Train Loss: 5.6198]
root: INFO: [Iteration:  14/ 50][Train Loss: 6.2886]
root: INFO: [Iteration:  15/ 50][Train Loss: 5.3805]
root: INFO: [Iteration:  16/ 50][Train Loss: 5.5352]
root: INFO: [Iteration:  17/ 50][Train Loss: 5.3096]
root: INFO: [Iteration:  18/ 50][Train Loss: 4.9605]
root: INFO: [Iteration:  19/ 50][Train Loss: 5.2883]
root: INFO: [Iteration:  20/ 50][Train Loss: 4.2874]
root: INFO: [Iteration:  21/ 50][Train Loss: 8.9987]
root: INFO: [Iteration:  22/ 50][Train Loss: 9.1299]
root: INFO: [Iteration:  23/ 50][Train Loss: 9.8137]
root: INFO: [Iteration:  24/ 50][Train Loss: 9.3217]
root: INFO: [Iteration:  25/ 50][Train Loss: 7.7921]
root: INFO: [Iteration:  26/ 50][Train Loss: 8.7621]
root: INFO: [Iteration:  27/ 50][Train Loss: 8.7424]
root: INFO: [Iteration:  28/ 50][Train Loss: 8.6468]
root: INFO: [Iteration:  29/ 50][Train Loss: 8.7177]
root: INFO: [Iteration:  30/ 50][Train Loss: 8.0810]
root: INFO: [Iteration:  31/ 50][Train Loss: 9.1243]
root: INFO: [Iteration:  32/ 50][Train Loss: 9.9793]
root: INFO: [Iteration:  33/ 50][Train Loss: 9.1434]
root: INFO: [Iteration:  34/ 50][Train Loss: 8.7449]
root: INFO: [Iteration:  35/ 50][Train Loss: 9.8128]
root: INFO: [Iteration:  36/ 50][Train Loss: 8.2927]
root: INFO: [Iteration:  37/ 50][Train Loss: 9.4342]
root: INFO: [Iteration:  38/ 50][Train Loss: 9.3299]
root: INFO: [Iteration:  39/ 50][Train Loss: 10.2795]
root: INFO: [Iteration:  40/ 50][Train Loss: 9.4234]
root: INFO: [Iteration:  41/ 50][Train Loss: 10.2457]
root: INFO: [Iteration:  42/ 50][Train Loss: 10.0058]
root: INFO: [Iteration:  43/ 50][Train Loss: 9.9598]
root: INFO: [Iteration:  44/ 50][Train Loss: 8.8804]
root: INFO: [Iteration:  45/ 50][Train Loss: 9.2593]
root: INFO: [Iteration:  46/ 50][Train Loss: 9.3517]
root: INFO: [Iteration:  47/ 50][Train Loss: 9.2039]
root: INFO: [Iteration:  48/ 50][Train Loss: 10.1497]
root: INFO: [Iteration:  49/ 50][Train Loss: 8.9243]
root: INFO: [Evaluation: mAP: 0.9633]
root: INFO: Namespace(arch='resnet50', batch_size=64, bits='12,24,32,48', epochs=3, gamma=200, gpu='6', learning_rate=0.001, max_iter=50, num_samples=2000)
root: INFO: 48
root: INFO: [Comment: learning rate decay]
root: INFO: [Iteration:   0/ 50][Train Loss: 239.0702]
root: INFO: [Iteration:   1/ 50][Train Loss: 63.4977]
root: INFO: [Iteration:   2/ 50][Train Loss: 30.6467]
root: INFO: [Iteration:   3/ 50][Train Loss: 26.8341]
root: INFO: [Iteration:   4/ 50][Train Loss: 23.3040]
root: INFO: [Iteration:   5/ 50][Train Loss: 18.0811]
root: INFO: [Iteration:   6/ 50][Train Loss: 22.9705]
root: INFO: [Iteration:   7/ 50][Train Loss: 20.9720]
root: INFO: [Iteration:   8/ 50][Train Loss: 17.2345]
root: INFO: [Iteration:   9/ 50][Train Loss: 14.0645]
root: INFO: [Iteration:  10/ 50][Train Loss: 19.1644]
root: INFO: [Iteration:  11/ 50][Train Loss: 18.7688]
root: INFO: [Iteration:  12/ 50][Train Loss: 17.4662]
root: INFO: [Iteration:  13/ 50][Train Loss: 15.0164]
root: INFO: [Iteration:  14/ 50][Train Loss: 13.8249]
root: INFO: [Iteration:  15/ 50][Train Loss: 14.0746]
root: INFO: [Iteration:  16/ 50][Train Loss: 13.4705]
root: INFO: [Iteration:  17/ 50][Train Loss: 14.1441]
root: INFO: [Iteration:  18/ 50][Train Loss: 15.4115]
root: INFO: [Iteration:  19/ 50][Train Loss: 12.3882]
root: INFO: [Iteration:  20/ 50][Train Loss: 14.8305]
root: INFO: [Iteration:  21/ 50][Train Loss: 26.1652]
root: INFO: [Iteration:  22/ 50][Train Loss: 24.8157]
root: INFO: [Iteration:  23/ 50][Train Loss: 24.1857]
root: INFO: [Iteration:  24/ 50][Train Loss: 23.6102]
root: INFO: [Iteration:  25/ 50][Train Loss: 22.5922]
root: INFO: [Iteration:  26/ 50][Train Loss: 22.9207]
root: INFO: [Iteration:  27/ 50][Train Loss: 20.4303]
root: INFO: [Iteration:  28/ 50][Train Loss: 21.0424]
root: INFO: [Iteration:  29/ 50][Train Loss: 25.4541]
root: INFO: [Iteration:  30/ 50][Train Loss: 18.5909]
root: INFO: [Iteration:  31/ 50][Train Loss: 22.8777]
root: INFO: [Iteration:  32/ 50][Train Loss: 25.2055]
root: INFO: [Iteration:  33/ 50][Train Loss: 23.6687]
root: INFO: [Iteration:  34/ 50][Train Loss: 24.9373]
root: INFO: [Iteration:  35/ 50][Train Loss: 23.9731]
root: INFO: [Iteration:  36/ 50][Train Loss: 25.6295]
root: INFO: [Iteration:  37/ 50][Train Loss: 25.3859]
root: INFO: [Iteration:  38/ 50][Train Loss: 24.1103]
root: INFO: [Iteration:  39/ 50][Train Loss: 25.2113]
root: INFO: [Iteration:  40/ 50][Train Loss: 23.4738]
root: INFO: [Iteration:  41/ 50][Train Loss: 23.3135]
root: INFO: [Iteration:  42/ 50][Train Loss: 22.6941]
root: INFO: [Iteration:  43/ 50][Train Loss: 27.2367]
root: INFO: [Iteration:  44/ 50][Train Loss: 26.4068]
root: INFO: [Iteration:  45/ 50][Train Loss: 24.4703]
root: INFO: [Iteration:  46/ 50][Train Loss: 25.5364]
root: INFO: [Iteration:  47/ 50][Train Loss: 24.7752]
root: INFO: [Iteration:  48/ 50][Train Loss: 26.3537]
root: INFO: [Iteration:  49/ 50][Train Loss: 25.4612]
root: INFO: [Evaluation: mAP: 0.9605]
